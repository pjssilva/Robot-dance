{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New case studies for Robot Dance paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import rc\n",
    "rc(\"text\", usetex=True)\n",
    "rc(\"font\", family=\"serif\")\n",
    "\n",
    "import run_robot\n",
    "import prepare_data\n",
    "reload(run_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Subnotification factor\n",
    "\n",
    "Between 21st and 29th of July the city of São Paulo made public the result of a research that [17.9% of its population](https://www1.folha.uol.com.br/equilibrioesaude/2020/08/em-sao-paulo-22-dos-moradores-dos-bairros-mais-pobres-ja-pegaram-coronavirus.shtml) had alredy had Covid-19. Here we use that number to find out a reasonable subnotification factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_prm = prepare_data.save_basic_parameters(min_level=0.8, rep=2.5, ndays=30)\n",
    "subnot_factor = 11.6\n",
    "cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"SP\"], 10000000, subnot_factor, 1, \"data/report_covid_with_drs_07_29.csv\")\n",
    "cities_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define some important decisions:\n",
    "\n",
    "* The basic reproduction rate (R0). The original literature and our own estimates suggest 2.5. But this value seems high nowdays when people are wearing masks, have learned stricter hygiene habits (more hand wahing), and do basic social distancing. I am trying now with 1.8.\n",
    "\n",
    "* Horizon of simulation: we use a little more than one year because after that we should probably have a vacine and the game changes completely.\n",
    "\n",
    "* Mean stay in ICU: mean time in ICU, it will also be used to select the right time series to estimate the number of ICU needed below. We are using 7.\n",
    "\n",
    "* Lockdown level: what is the reproduction level achievable by a strict lockdown. We are using 0.8. Should be smaller than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the basic data for the case studies\n",
    "\n",
    "# Basic reproduction number\n",
    "basic_rep = 1.8\n",
    "\n",
    "# Simulation horizon\n",
    "# A little more than a year when thevaccine should be here\n",
    "ndays = 14*2*14\n",
    "\n",
    "# Mean time in ICU\n",
    "time_icu = 7\n",
    "\n",
    "# Lockdown level\n",
    "lock_level = 0.8\n",
    "\n",
    "# Define basic paramters\n",
    "basic_prm = prepare_data.save_basic_parameters(min_level=lock_level, rep=basic_rep, time_icu=time_icu, ndays=ndays)\n",
    "\n",
    "# Compute initial values\n",
    "\n",
    "# For cities\n",
    "# cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"Araçatuba\", \"São José Do Rio Preto\"], 500000, 1)\n",
    "# cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"São José Do Rio Preto\"], 25000, 6, 1)\n",
    "\n",
    "# For DRS\n",
    "cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [], 000000, subnot_factor, 1, \"data/report_covid_with_drs_07_01.csv\")\n",
    "\n",
    "# Sub-groups for figures\n",
    "sp = [\"SP\"]\n",
    "sp_so = sp + [\"SW\"]\n",
    "masp_names = sp + [\"E\", \"N\", \"W\", \"SE\", \"SW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target matrix (max infected level)\n",
    "ncities, ndays = len(cities_data.index), int(basic_prm[\"ndays\"])\n",
    "target = 0.8*np.ones((ncities, ndays))\n",
    "target = prepare_data.save_target(cities_data, target)\n",
    "\n",
    "# Use a forcedif that releases the cities in the end\n",
    "force_dif = np.ones((ncities, ndays))\n",
    "cities_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add information on the time series that estimate the need of ICUs\n",
    "\n",
    "We are using the time series adjusted considering that the mean ICU stay is 7 days (which lead to larger ICU capacity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if basic_prm[\"time_icu\"] == 11:\n",
    "    # Time series adjusted considering the mean ICU time is 11 days\n",
    "    ts_sp = np.array([0.0074335, 0.01523406, -0.00186355, 0.0, 1.67356018, -0.68192908, np.sqrt(0.00023883),\n",
    "        0.007682840158843, 0.007536060983504])\n",
    "    ts_notsp = np.array([0.00520255, 0.01532709, 0.00044498, 0.0, 1.75553282, -0.76360711, np.sqrt(3.567E-05),\n",
    "        0.005426447471187, 0.005282217308748])\n",
    "elif basic_prm[\"time_icu\"] == 7:\n",
    "    # Time series adjusted considering the mean ICU time is 7 days\n",
    "    ts_sp = np.array([0.01099859, 0.02236023, 0.00370254, 0.0, 1.79119571, -0.80552926, np.sqrt(0.00034005),\n",
    "        0.011644768910252, 0.011221496171591])\n",
    "    ts_notsp = np.array([0.0076481, 0.0218084, 0.00367839, 0.0, 1.81361379, -0.82550856, np.sqrt(8.028E-05),\n",
    "        0.007907216664912, 0.007721801045322])\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Index of the cities that form the Metropolitan area of São Paulo\n",
    "MASP = np.array([7, 10, 15, 16, 17, 22]) - 1\n",
    "\n",
    "ts_drs = np.ones((len(cities_data), len(ts_notsp)))\n",
    "ts_drs *= ts_notsp\n",
    "ts_drs[MASP, :] = ts_sp\n",
    "ts_drs = pd.DataFrame(data=ts_drs, index=cities_data.index, columns=[\n",
    "    \"rho_min\", \"rho_max\", \"intercept\", \"trend\", \"phi_1\", \"phi_2\", \"sigma_omega\", \"state0\", \"state_less_1\"\n",
    "])\n",
    "ts_drs[\"confidence\"] = 0.9\n",
    "ts_drs[\"time_icu\"] = time_icu\n",
    "cities_data = pd.concat([cities_data, ts_drs], axis=1)\n",
    "cities_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Simple function to run a test and save results\n",
    "def run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif, pools=None, verbosity=1):\n",
    "    run_robot.prepare_optimization(basic_prm, cities_data, M, target, hammer_data, force_dif, pools, verbosity=verbosity)\n",
    "    run_robot.optimize_and_show_results(basic_prm, figure_file, result_file, cities_data, target, verbosity=verbosity)\n",
    "    result = pd.read_csv(result_file, index_col=[0, 1])\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_sp.png\", hammer_data.loc[sp, \"duration\"].values, \n",
    "        cities_data[\"start_date\"][0], sp)\n",
    "    plt.savefig(figure_file[:-4] + \"_sp.png\", dpi=150, bbox_inches='tight')\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_spso.png\", hammer_data.loc[sp_so, \"duration\"].values, \n",
    "        cities_data[\"start_date\"][0], sp_so)\n",
    "    plt.savefig(figure_file[:-4] + \"_sp_so.png\", dpi=150, bbox_inches='tight')\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_rmsp.png\", \n",
    "        hammer_data.loc[masp_names, \"duration\"].values, cities_data[\"start_date\"][0], masp_names)\n",
    "    plt.savefig(figure_file[:-4] + \"_rmsp.png\", dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: 14 day window, no alternation, no mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mobility matrix.\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=0, drs=\"data/report_drs_mobility.csv\")\n",
    "hammer_data = prepare_data.save_hammer_data(cities_data, 0, basic_prm[\"min_level\"])\n",
    "run_robot.find_feasible_hammer(basic_prm, cities_data, M, target, hammer_data, out_file=None, \n",
    "    incr_all=True, verbosity=1)\n",
    "M.loc[\"SP\", \"SW\"], M.loc[\"SW\", \"SP\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_nomobility.csv\"\n",
    "figure_file = \"results/window_14_noalt_nomobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: 14 day window, no alternation, with mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mobility matrix (full connection)\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=22, drs=\"data/report_drs_mobility.csv\")\n",
    "hammer_data = prepare_data.save_hammer_data(cities_data, 0, basic_prm[\"min_level\"])\n",
    "run_robot.find_feasible_hammer(basic_prm, cities_data, M, target, hammer_data, out_file=None, \n",
    "    incr_all=True, verbosity=1)\n",
    "M.loc[\"SP\", \"SW\"], M.loc[\"SW\", \"SP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_withmobility.csv\"\n",
    "figure_file = \"results/window_14_noalt_withmobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: 14 day window, with alternation, with mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start searching for when the \"no alternation\" solution decided for full opening.\n",
    "results = pd.read_csv(\"results/window_14_noalt_withmobility.csv\")\n",
    "results = results[results[\"Variable\"] == \"rt\"]\n",
    "results.drop([\"Variable\"], axis=1, inplace=True)\n",
    "results.set_index(\"City\", inplace=True)\n",
    "\n",
    "def find_last_opening(rts, rep):\n",
    "    \"\"\"Find the first moment where the decision of the nonalternating solution is\n",
    "    to fully open the region.\n",
    "    \"\"\"\n",
    "    rts = rts.values.copy()\n",
    "    rts[rts < 0.95*rep] = 0.0\n",
    "    return len(rts) - rts[::-1].argmin() + 1\n",
    "\n",
    "# Turn off alternation after two windows after the time needed for opening.\n",
    "for i in range(len(results.index)):\n",
    "    opening = find_last_opening(results.iloc[i,:], basic_prm[\"rep\"])\n",
    "    force_dif[i, opening + 2*int(basic_prm[\"window\"]):] = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set up alternation weight\n",
    "basic_prm[\"alternate\"] = 1.0\n",
    "result_file = \"results/window_14_withalt_withmobility.csv\"\n",
    "figure_file = \"results/window_14_withalt_withmobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)"
   ]
  },
  {
   "source": [
    "## Case 4: 14 day window, no alternation, link SP - SW broken"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mobility matrix (full connection)\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=22, drs=\"data/report_drs_mobility.csv\")\n",
    "# Destroy the link between SP and SW\n",
    "M.loc[\"SP\", \"SW\"], M.loc[\"SW\", \"SP\"] = 0, 0\n",
    "hammer_data = prepare_data.save_hammer_data(cities_data, 0, basic_prm[\"min_level\"])\n",
    "run_robot.find_feasible_hammer(basic_prm, cities_data, M, target, hammer_data, out_file=None, \n",
    "    incr_all=True, verbosity=1)\n",
    "M.loc[\"SP\", \"SW\"], M.loc[\"SW\", \"SP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "force_dif =  np.ones((ncities, ndays))\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_withmobility_no_link_sp_sw.csv\"\n",
    "figure_file = \"results/window_14_noalt_withmobility_no_link_sp_sw.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 5: 14 day window, no alternation, with mobility, ICU shared in metropolitan area from day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mobility matrix (full connection)\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=22, drs=\"data/report_drs_mobility.csv\")\n",
    "hammer_data = prepare_data.save_hammer_data(cities_data, 0, basic_prm[\"min_level\"])\n",
    "run_robot.find_feasible_hammer(basic_prm, cities_data, M, target, hammer_data, out_file=None, \n",
    "    incr_all=True, verbosity=1)\n",
    "M.loc[\"SP\", \"SW\"], M.loc[\"SW\", \"SP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Pool with all Sao Paulo metropolitan area\n",
    "pools = list([[i + 1] for i in range(0, 22) if i not in MASP])\n",
    "pools.append(list([i + 1 for i in MASP]))\n",
    "\n",
    "force_dif =  np.ones((ncities, ndays))\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_withmobility_icushared.csv\"\n",
    "figure_file = \"results/window_14_noalt_withmobility_icushared.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif, pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code to check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "pool = MASP\n",
    "total_duration = int(basic_prm[\"ndays\"])\n",
    "first_day = 0 #hammer_data.iloc[pool, 0].min()\n",
    "last_day = total_duration #first_day + 50 + 1\n",
    "simulation = pd.read_csv(\"results/window_14_noalt_withmobility_icushared.csv\", index_col=[0, 1])\n",
    "\n",
    "cities_names = cities_data.iloc[pool].index\n",
    "population = cities_data[\"population\"]\n",
    "icu_capacity = cities_data[\"icu_capacity\"]\n",
    "total_icus = np.array([(target.loc[c]*population.loc[c]*icu_capacity.loc[c]).values for c in cities_names]).sum(axis=0)\n",
    "total_icus = total_icus[first_day:last_day]\n",
    "\n",
    "# Plot mean \n",
    "c = cities_names[0]\n",
    "icus = simulation.loc[c, \"mean_used_icu\"]\n",
    "for c in cities_names[1:]:\n",
    "    icus += simulation.loc[c, \"mean_used_icu\"]\n",
    "plt.plot(icus[first_day:last_day], color=\"C0\", label=\"ICU occupation\")\n",
    "simuls = {\"mean\": icus}\n",
    "\n",
    "# Plot upper bound\n",
    "c = cities_names[0]\n",
    "icus = simulation.loc[c, \"upper_used_icu\"]\n",
    "for c in cities_names[1:]:\n",
    "    icus += simulation.loc[c, \"upper_used_icu\"]\n",
    "plt.plot(icus[first_day:last_day], label=\"\", color=\"C0\")\n",
    "simuls[\"upper\"] = icus\n",
    "\n",
    "# Make random simulations\n",
    "time_series = run_robot.SimpleTimeSeries(*cities_data.iloc[pool[0], 7:-2])\n",
    "total_days = 0\n",
    "bad_days = 0\n",
    "for i in range(1000):\n",
    "    total_days += last_day - first_day\n",
    "    need_icu = time_series.simulate(total_duration, True)\n",
    "    used_icus = simulation.loc[cities_names[0], \"i\"]*need_icu*population[cities_names[0]]\n",
    "    for c in cities_names[1:]:\n",
    "        # TODO: Delete below\n",
    "        need_icu = time_series.simulate(total_duration, True)\n",
    "        used_icus += simulation.loc[c, \"i\"]*need_icu*population[c]\n",
    "    used_icus *= basic_prm[\"time_icu\"]/basic_prm[\"tinf\"]\n",
    "    used_icus = used_icus[first_day:last_day]\n",
    "    bad_days += (used_icus > total_icus).sum()\n",
    "    plt.plot(used_icus, label=\"\", alpha=0.025, color=\"C0\")\n",
    "    simuls[i] = used_icus\n",
    "\n",
    "print(f\"Bad days = {bad_days:d}/{total_days:d} == {bad_days / total_days * 100:f}%\")\n",
    "\n",
    "# Plot results\n",
    "import matplotlib.pylab as plt\n",
    "plt.plot(total_icus, color=\"C3\", label=\"Maximal ICU target\")\n",
    "simuls[\"target\"] = total_icus\n",
    "start_date = pd.Timestamp(cities_data[\"start_date\"][0]) + first_day*pd.to_timedelta(\"1D\")\n",
    "ticks = pd.date_range(start_date, start_date + (last_day - first_day)*pd.to_timedelta(\"1D\"), freq=\"2MS\")\n",
    "ticks = list(ticks)\n",
    "if ticks[0] <= start_date + pd.to_timedelta(\"10D\"):\n",
    "    ticks[0] = start_date\n",
    "else:\n",
    "    ticks = [start_date] + ticks\n",
    "plt.gca().set_xticks([(i - start_date).days for i in ticks])\n",
    "labels = [i.strftime('%m/%Y') for i in ticks]\n",
    "plt.gca().set_xticklabels(labels, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.title(\"Metropolitan Area of São Paulo - ICU occupation\")\n",
    "plt.savefig(\"results/icu_usage_with_mobility_sharing.png\", dpi=150, bbox_inches='tight')\n",
    "\n",
    "df = pd.DataFrame(simuls)\n",
    "df.T.to_csv(\"results/random_simuls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "def check_icus(basic_prm, cities_data, target, pool=MASP, first_day=0, last_day=-1, simulation_file=\"results/window_14_noalt_withmobility_icushared.csv\", reps=1000):\n",
    "    total_duration = int(basic_prm[\"ndays\"])\n",
    "    if last_day < 0:\n",
    "        last_day = total_duration - int(basic_prm[\"time_icu\"])\n",
    "    simulation = pd.read_csv(simulation_file, index_col=[0, 1])\n",
    "\n",
    "    cities_names = cities_data.iloc[pool].index\n",
    "    population = cities_data[\"population\"]\n",
    "    icu_capacity = cities_data[\"icu_capacity\"]\n",
    "    total_icus = np.array([(target.loc[c]*population.loc[c]*icu_capacity.loc[c]).values for c in cities_names]).sum(axis=0)\n",
    "    total_icus = total_icus[first_day:last_day]\n",
    "\n",
    "    # Make random simulations\n",
    "    time_series = run_robot.SimpleTimeSeries(*cities_data.iloc[pool[0], 7:-2])\n",
    "    total_days = 0\n",
    "    bad_days = np.zeros(last_day - first_day)\n",
    "    for i in range(reps):\n",
    "        total_days += last_day - first_day\n",
    "        need_icu = time_series.simulate(total_duration, True)\n",
    "        used_icus = simulation.loc[cities_names[0], \"i\"]*need_icu*population[cities_names[0]]\n",
    "        for c in cities_names[1:]:\n",
    "            # TODO: Delete below\n",
    "            need_icu = time_series.simulate(total_duration, True)\n",
    "            used_icus += simulation.loc[c, \"i\"]*need_icu*population[c]\n",
    "        used_icus *= basic_prm[\"time_icu\"]/basic_prm[\"tinf\"]\n",
    "        used_icus = used_icus[first_day:last_day]\n",
    "        bad_days += used_icus > total_icus\n",
    "\n",
    "    n_days = last_day - first_day\n",
    "    mean_violation = bad_days.sum() / total_days\n",
    "    n_violation = (bad_days > 0).sum()\n",
    "    mean_pos_violation = bad_days.sum() / (reps*n_violation)\n",
    "    max_violation = bad_days.max() / reps\n",
    "    return  n_days, n_violation, mean_violation, mean_pos_violation, max_violation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def quality_table(pools, pool_names, file_name, basic_prm, cities_data, target, hammer_duration, reps=1000):\n",
    "    quality_bench = {}\n",
    "    quality_bench[\"# days\"] = []\n",
    "    quality_bench[\"Bad days\"], quality_bench[\"Mean violation\"] = [], []\n",
    "    quality_bench[\"Mean violation in bad days\"], quality_bench[\"Max violation\"] = [], []\n",
    "    for p in pools:\n",
    "        print(p, end=\" \")\n",
    "        first_day = hammer_duration[p].min()\n",
    "        n_days, n_v, mean_v, mean_bad_v, max_v = check_icus(\n",
    "            basic_prm, cities_data, target, pool=p, first_day=first_day,\n",
    "            simulation_file=file_name, reps=reps)\n",
    "        quality_bench[\"# days\"].append(n_days)\n",
    "        quality_bench[\"Bad days\"].append(n_v)\n",
    "        quality_bench[\"Mean violation\"].append(mean_v)\n",
    "        quality_bench[\"Mean violation in bad days\"].append(mean_bad_v)\n",
    "        quality_bench[\"Max violation\"].append(max_v)\n",
    "\n",
    "    print()\n",
    "    return pd.DataFrame(quality_bench, index=pool_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suburbs = list(MASP).copy()\n",
    "suburbs.remove(15)\n",
    "pools = list([[i] for i in range(22) if i not in MASP])\n",
    "cities_names = list(cities_data.index[[p[0] for p in pools]])\n",
    "pools += [list(MASP), suburbs, [15]]\n",
    "cities_names += [\"MASP\", \"Suburbs\", \"São Paulo city\"]\n",
    "\n",
    "qt1 = quality_table(pools, cities_names, \"results/window_14_noalt_withmobility.csv\", \n",
    "    basic_prm, cities_data, target, hammer_data[\"duration\"].values, 10000)\n",
    "qt1.to_csv(\"results/icu_quality_icu_not_shared.csv\")\n",
    "qt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qt2 = quality_table(pools, cities_names, \n",
    "    \"results/window_14_noalt_withmobility_icushared.csv\", basic_prm, cities_data, target, hammer_data[\"duration\"], 10000)\n",
    "qt2.to_csv(\"results/icu_quality_icu_shared.csv\")\n",
    "qt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch area, you can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c = MASP[0]\n",
    "# time_series_data = cities_data.iloc[c, 7:-2]\n",
    "# confidence = cities_data.iloc[c, -2]\n",
    "# need_icu, upper_bound = get_rho_icu(ndays, time_series_data, confidence, True)\n",
    "# plt.plot(need_icu, color=\"C1\")\n",
    "# plt.plot(upper_bound, color=\"C1\")\n",
    "\n",
    "# #plt.plot(real_data_sp,color=\"C3\")\n",
    "# time_series = run_robot.SimpleTimeSeries(*time_series_data)\n",
    "# for i in range(100):\n",
    "#     time_series.reset()\n",
    "#     random_traj = [time_series.iterate(random=True) for i in range(ndays)]\n",
    "#     plt.plot(random_traj, color=\"C1\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# e_icu_interior, upper_interior = get_rho_icu(ndays, ts_notsp_7, 0.9, True)\n",
    "# e_icu_masp, upper_masp = get_rho_icu(ndays, ts_sp_7, 0.9, True)\n",
    "# pre_df = {\n",
    "#     \"SP rho_icu\": e_icu_masp, \"SP upper bound\": upper_masp, \n",
    "#     \"Interior rho_icu\": e_icu_interior, \"Interior upper bound\": upper_interior\n",
    "# }\n",
    "# df = pd.DataFrame(pre_df)\n",
    "# df.to_csv(\"rho_icu.csv\")\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}