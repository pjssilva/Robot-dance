{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New case studies for Robot Dance paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import run_robot\n",
    "import prepare_data\n",
    "reload(run_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Subnotification factor\n",
    "\n",
    "Between 21st and 29th of July the city of São Paulo made public the result of a research that [17.9% of its population](https://www1.folha.uol.com.br/equilibrioesaude/2020/08/em-sao-paulo-22-dos-moradores-dos-bairros-mais-pobres-ja-pegaram-coronavirus.shtml) had alredy had Covid-19. Here we use that number to find out a reasonable subnotification factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_prm = prepare_data.save_basic_parameters(min_level=0.8, rep=2.5, ndays=30)\n",
    "subnot_factor = 11.6\n",
    "cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"Mun. São Paulo\"], 10000000, subnot_factor, 1, \"data/covid_with_drs_07_29.csv\")\n",
    "cities_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define some important decisions:\n",
    "\n",
    "* The basic reproduction rate (R0). The original literature and our own estimates suggest 2.5. But this value seems high nowdays when people are wearing masks, have learned stricter hygiene habits (more hand wahing), and do basic social distancing. I am trying now with 1.8.\n",
    "\n",
    "* Horizon of simulation: we use a little more than one year because after that we should probably have a vacine and the game changes completely.\n",
    "\n",
    "* What time series to use: we are using 7 days (which lead to larger ICU capacity).\n",
    "\n",
    "* Lockdown level: what is the reproduction level achievable by a strict lockdown. We are using 0.8. Should be smaller than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the basic data for the case studies\n",
    "\n",
    "# Basic reproduction number\n",
    "basic_rep = 1.8\n",
    "\n",
    "# Simulation horizon\n",
    "# A little more than a year when thevaccine should be here\n",
    "ndays = 14*2*14\n",
    "\n",
    "# Time series\n",
    "need_icu = 0.00693521103887298\n",
    "time_icu = 7\n",
    "#need_icu = 0.00650997\n",
    "#time_icu = 11\n",
    "\n",
    "# Lockdown level\n",
    "lock_level = 0.8\n",
    "\n",
    "# Define basic paramters\n",
    "basic_prm = prepare_data.save_basic_parameters(min_level=lock_level, rep=basic_rep, ndays=ndays, need_icu=need_icu, time_icu=time_icu)\n",
    "\n",
    "# Compute initial values\n",
    "\n",
    "# For cities\n",
    "# cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"Araçatuba\", \"São José Do Rio Preto\"], 500000, 1)\n",
    "# cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [\"São José Do Rio Preto\"], 25000, 6, 1)\n",
    "\n",
    "# For DRS\n",
    "cities_data = prepare_data.compute_initial_condition_evolve_and_save(basic_prm, \"SP\", [], 000000, subnot_factor, 1, \"data/covid_with_drs_07_01.csv\")\n",
    "\n",
    "# Sub-groups for figures\n",
    "sp = [\"Mun. São Paulo\"]\n",
    "sp_so = sp + [\"Sub região sudoeste - RMSP\"]\n",
    "rmsp = sp + [\"Sub região leste - RMSP\", \"Sub região norte - RMSP\", \"Sub região oeste - RMSP\", \"Sub região sudeste - RMSP\", \"Sub região sudoeste - RMSP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target matrix (max infected level)\n",
    "ncities, ndays = len(cities_data.index), int(basic_prm[\"ndays\"])\n",
    "target = 0.8*np.ones((ncities, ndays))\n",
    "target = prepare_data.save_target(cities_data, target)\n",
    "\n",
    "# Use a forcedif that releases the cities in the end\n",
    "force_dif = np.ones((ncities, ndays))\n",
    "cities_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Simple function to run a test and save results\n",
    "def run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif, pools=None, verbosity=1):\n",
    "    hammer_data = prepare_data.save_hammer_data(cities_data, 0, basic_prm[\"min_level\"])\n",
    "    run_robot.find_feasible_hammer(basic_prm, cities_data, M, target, hammer_data, out_file=None, \n",
    "        incr_all=True, verbosity=verbosity)\n",
    "    run_robot.prepare_optimization(basic_prm, cities_data, M, target, hammer_data, force_dif, pools, verbosity=verbosity)\n",
    "    run_robot.optimize_and_show_results(basic_prm, figure_file, result_file, cities_data, verbosity=verbosity)\n",
    "    result = pd.read_csv(result_file, index_col=[0, 1])\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_sp.png\", hammer_data[\"duration\"].values, \n",
    "        cities_data[\"start_date\"][0], sp)\n",
    "    plt.savefig(figure_file[:-4] + \"_sp.png\", dpi=150, bbox_inches='tight')\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_spso.png\", hammer_data[\"duration\"].values, \n",
    "        cities_data[\"start_date\"][0], sp_so)\n",
    "    plt.savefig(figure_file[:-4] + \"_sp_so.png\", dpi=150, bbox_inches='tight')\n",
    "    run_robot.plot_result(basic_prm, result, figure_file[:-4] + \"_rmsp.png\", hammer_data[\"duration\"].values, \n",
    "        cities_data[\"start_date\"][0], rmsp)\n",
    "    plt.savefig(figure_file[:-4] + \"_rmsp.png\", dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: 14 day window, no alternation, no mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mobility matrix.\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=0, drs=True)\n",
    "M.loc[\"Mun. São Paulo\", \"Sub região sudoeste - RMSP\"], M.loc[\"Sub região sudoeste - RMSP\", \"Mun. São Paulo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_nomobility.csv\"\n",
    "figure_file = \"results/window_14_noalt_nomobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: 14 day window, no alternation, with mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mobility matrix (full connection)\n",
    "M = prepare_data.convert_mobility_matrix_and_save(cities_data, max_neighbors=22, drs=True)\n",
    "M.loc[\"Mun. São Paulo\", \"Sub região sudoeste - RMSP\"], M.loc[\"Sub região sudoeste - RMSP\", \"Mun. São Paulo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_withmobility.csv\"\n",
    "figure_file = \"results/window_14_noalt_withmobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: 14 day window, with alternation, with mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start searching for when the \"no alternation\" solution decided for full opening.\n",
    "results = pd.read_csv(\"results/window_14_noalt_withmobility.csv\")\n",
    "results = results[results[\"Variable\"] == \"rt\"]\n",
    "results.drop([\"Variable\"], axis=1, inplace=True)\n",
    "results.set_index(\"City\", inplace=True)\n",
    "\n",
    "def find_last_opening(rts, rep):\n",
    "    \"\"\"Find the first moment where the decision of the nonalternating solution is\n",
    "    to fully open the region.\n",
    "    \"\"\"\n",
    "    rts = rts.values.copy()\n",
    "    rts[rts < 0.95*rep] = 0.0\n",
    "    return len(rts) - rts[::-1].argmin() + 1\n",
    "\n",
    "# Turn off alternation after two windows after the time needed for opening.\n",
    "for i in range(len(results.index)):\n",
    "    opening = find_last_opening(results.iloc[i,:], basic_prm[\"rep\"])\n",
    "    force_dif[i, opening + 2*int(basic_prm[\"window\"]):] = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set up alternation weight\n",
    "basic_prm[\"alternate\"] = 1.0\n",
    "result_file = \"results/window_14_withalt_withmobility.csv\"\n",
    "figure_file = \"results/window_14_withalt_withmobility.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4: 14 day window, no alternation, with mobility, ICU shared in metropolitan area from day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Pool with all Sao Paulo metropolitan area\n",
    "pools = [[1], [2], [3], [4], [5], [6], [7],[8], [9, 15, 16, 17, 18, 19], [10], [11], \n",
    "         [12], [13], [14], [20], [21], [22]]\n",
    "\n",
    "force_dif =  np.ones((ncities, ndays))\n",
    "basic_prm[\"alternate\"] = 0.0\n",
    "result_file = \"results/window_14_noalt_withmobility_icushared.csv\"\n",
    "figure_file = \"results/window_14_noalt_withmobility_icushared.png\"\n",
    "run_a_test(basic_prm, result_file, figure_file, cities_data, M, target, force_dif, pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code to check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool = np.array([19]) #np.array([9, 15, 16, 17, 18, 19]) - 1\n",
    "cities_names = cities_data.iloc[pool].index\n",
    "population = cities_data[\"population\"]\n",
    "icu_capacity = cities_data[\"icu_capacity\"]\n",
    "total_icus = np.array([(target.loc[c]*population.loc[c]*icu_capacity.loc[c]).values for c in cities_names]).sum(axis=0)\n",
    "simulation = pd.read_csv(\"results/window_14_noalt_withmobility.csv\", index_col=[0, 1])\n",
    "#simulation = pd.read_csv(\"results/window_14_withalt_withmobility.csv\", index_col=[0, 1])\n",
    "\n",
    "first_day = 0 #hammer_data.iloc[pool, 0].min()\n",
    "last_day = int(basic_prm[\"ndays\"]) #first_day + 50 + 1\n",
    "total_icus = total_icus[first_day:last_day]\n",
    "\n",
    "if basic_prm[\"time_icu\"] == 7:\n",
    "    time_series_parameters = [0.00951258, 0.02407533, 0.01565422, 0.0, 1.04877035, -0.07470716, np.sqrt(0.00413135),\n",
    "        0.01020326268631, 0.009768267929635]\n",
    "    # time_series_parameters = [0.00926221, 0.01963079, 0.01034362, 0.0, 1.20388368, -0.22446884, np.sqrt(0.00495803),                    0.009882415226021, 0.010207401448971]\n",
    "    # time_series_parameters =  [0.00683802, 0.02407533, 0.00483438, 0.0, 1.08987579, -0.09888466, np.sqrt(0.00210162), \n",
    "    # 0.007187944540946, 0.006838016532435]\n",
    "elif basic_prm[\"time_icu\"] == 11:\n",
    "    time_series_parameters = [0.00643884, 0.01740896, 0.0112156, 0.0, 1.10547981, -0.1245054, np.sqrt(0.00368004),\n",
    "        0.00692964502549, 0.006645629100376]\n",
    "    # time_series_parameters = [0.00496131, 0.01740896, 0.0043539, 0.0, 1.12791817, -0.13644296, np.sqrt(0.00189557), \n",
    "    #     0.005290328560701, 0.004961305864535]\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Plot mean \n",
    "time_series = run_robot.SimpleTimeSeries(*time_series_parameters)\n",
    "need_icu = [time_series.iterate(random=False) for i in range(int(basic_prm[\"ndays\"]))]\n",
    "used_icus = simulation.loc[cities_names[0], \"i\"]*need_icu*population[cities_names[0]]\n",
    "for c in cities_names[1:]:\n",
    "    used_icus += simulation.loc[c, \"i\"]*need_icu*population[c]\n",
    "used_icus *= basic_prm[\"time_icu\"]/basic_prm[\"tinf\"]\n",
    "used_icus = used_icus[first_day:last_day]\n",
    "plt.plot(used_icus, color=\"C0\", label=\"ICU occupation\")\n",
    "\n",
    "# Plot upper bound\n",
    "p = 0.1\n",
    "F1p = stats.norm.ppf(1.0 - p)\n",
    "theta = np.array(time_series.theta).copy()\n",
    "upper_bound = need_icu[:]\n",
    "for j in range(len(upper_bound)):\n",
    "    upper_bound[j] += F1p*time_series.sigmaw*time_series.delta*np.sqrt((theta[:j + 1]**2).sum())\n",
    "used_icus = simulation.loc[cities_names[0], \"i\"]*upper_bound*population[cities_names[0]]\n",
    "for c in cities_names[1:]:\n",
    "    used_icus += simulation.loc[c, \"i\"]*upper_bound*population[c]\n",
    "used_icus *= basic_prm[\"time_icu\"]/basic_prm[\"tinf\"]\n",
    "used_icus = used_icus[first_day:last_day]\n",
    "plt.plot(used_icus, label=\"\", color=\"C0\")\n",
    "\n",
    "# Make random simulations\n",
    "total_days = 0\n",
    "bad_days = 0\n",
    "for i in range(100):\n",
    "    time_series.reset()\n",
    "    total_days += last_day - first_day\n",
    "    need_icu = [time_series.iterate(random=True) for i in range(int(basic_prm[\"ndays\"]))]\n",
    "    used_icus = simulation.loc[cities_names[0], \"i\"]*need_icu*population[cities_names[0]]\n",
    "    for c in cities_names[1:]:\n",
    "        used_icus += simulation.loc[c, \"i\"]*need_icu*population[c]\n",
    "    used_icus *= basic_prm[\"time_icu\"]/basic_prm[\"tinf\"]\n",
    "    used_icus = used_icus[first_day:last_day]\n",
    "    bad_days += (used_icus > total_icus).sum()\n",
    "    plt.plot(used_icus, label=\"\", alpha=0.2, color=\"C0\")\n",
    "\n",
    "print(f\"Bad days = {bad_days:d}/{total_days:d} == {bad_days / total_days * 100:f}%\")\n",
    "\n",
    "# Plot results\n",
    "import matplotlib.pylab as plt\n",
    "plt.plot(total_icus, color=\"C3\", label=\"Maximal ICU target\")\n",
    "start_date = pd.Timestamp(cities_data[\"start_date\"][0]) + first_day*pd.to_timedelta(\"1D\")\n",
    "ndays = len(simulation.loc[cities_names[0], \"i\"])\n",
    "ticks = pd.date_range(start_date, start_date + (last_day - first_day)*pd.to_timedelta(\"1D\"), freq=\"1MS\")\n",
    "ticks = list(ticks)\n",
    "if ticks[0] <= start_date + pd.to_timedelta(\"10D\"):\n",
    "    ticks[0] = start_date\n",
    "else:\n",
    "    ticks = [start_date] + ticks\n",
    "plt.gca().set_xticks([(i - start_date).days for i in ticks])\n",
    "labels = [i.strftime('%d/%m/%Y') for i in ticks]\n",
    "plt.gca().set_xticklabels(labels, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.savefig(\"results/icu-usage.png\", dpi=150, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch area, you can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(run_robot)\n",
    "from scipy.stats import norm\n",
    "duration = 40\n",
    "if basic_prm[\"time_icu\"] == 7:\n",
    "    time_series_data = [0.00951258, 0.02407533, 0.01565422, 0.0, 1.04877035, -0.07470716, np.sqrt(0.00413135),\n",
    "        0.01020326268631, 0.009768267929635]\n",
    "elif basic_prm[\"time_icu\"] == 11:\n",
    "    time_series_data = [0.00643884, 0.01740896, 0.0112156, 0.0, 1.10547981, -0.1245054, np.sqrt(0.00368004),\n",
    "        0.00692964502549, 0.006645629100376]\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "time_series = run_robot.SimpleTimeSeries(*time_series_data)\n",
    "eicu = [time_series.iterate() for i in range(duration)]\n",
    "p = 0.1\n",
    "F1p = norm.ppf(1.0 - p)\n",
    "theta = np.array(time_series.theta).copy()\n",
    "upper_bound = eicu[:]\n",
    "for i in range(duration):\n",
    "    upper_bound[i] += F1p*time_series.sigmaw*time_series.delta*np.sqrt((theta[:i + 1]**2).sum())\n",
    "sample_icu = []\n",
    "nsamples = 0\n",
    "nOK = 0\n",
    "for i in range(1000):\n",
    "    start, stop = 0, duration + 1\n",
    "    time_series.reset()\n",
    "    samples = np.array([time_series.iterate(random=True) for i in range(duration)])\n",
    "    sample_icu.append(samples)\n",
    "    nsamples += len(samples[start:stop])\n",
    "    nOK += (samples[start:stop] <= upper_bound[start:stop]).sum()\n",
    "\n",
    "print(nOK, nsamples, 100*nOK/nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload(run_robot)\n",
    "duration = 365\n",
    "constant_fix = [0.00679005, 0.10136368, 0.00586580, 0.0, 1.97210897, -0.97759272, np.sqrt(0.00051777), \n",
    "    0.007307625663244, 0.007008117960396]\n",
    "constant_trend_fix = [0.00679005, 0.10136368, 0.02727935, -0.00126350, 0.52217732, 0.42334116, np.sqrt(0.00656118),      \n",
    "    0.007307625663244, 0.007008117960396]\n",
    "trend_fix = [0.00679005, 0.10136368, 0.0, 0.00004587, 1.96641774, -0.96871210, np.sqrt(0.00057691),\n",
    "    0.007307625663244, 0.007008117960396]\n",
    "old = [0.00379873, 0.02360889, 0.003055220184503005, 0.0, 1.346540496346441, -0.35212183634836325, np.sqrt(0.0011820962652620602),\n",
    "    0.009821952043627, 0.009099877277162]\n",
    "    \n",
    "constant_fix_new = [0.00679005, 0.01835854, 0.0112156, 0.0, 1.10547981, -0.1245054, np.sqrt(0.00368004), \n",
    "    0.007307625663244, 0.007008117960396]\n",
    "trend_fix_new = [0.00679005, 0.01835854, 0.0, -0.00035806, 1.08276406, -0.0860476, np.sqrt(0.0036272),\n",
    "    0.007307625663244, 0.007008117960396]\n",
    "constant_trend_fix_new = [0.00679005, 0.01835854, 0.35433314, -0.00937098, 0.84891778, -0.25056312, np.sqrt(0.00294438),\n",
    "    0.007307625663244, 0.007008117960396]\n",
    "\n",
    "constant_7 = [0.01003145, 0.02538853, 0.0156431, 0.0, 1.04906141, -0.07498674, np.sqrt(0.00412906),\n",
    "    0.007307625663244, 0.007008117960396]\n",
    "\n",
    "\n",
    "real_data = [0.009653179181505, 0.009523875134098, 0.009444887860431, 0.009262212993882, 0.009478777174599, 0.010093499807287, 0.010179820005892, 0.010292394029863, 0.010528625867502, 0.010474377255532, 0.00995980626524, 0.009882852156456, 0.010547373988112, 0.010420737340341, 0.010247061232653, 0.01000847542721, 0.010060900166336, 0.009882415226021, 0.010207401448971, 0.011062869458313, 0.011366884433894, 0.011588585778359, 0.011596446414382, 0.011190661353815, 0.010490634335358, 0.009821952043627, 0.009099877277162, 0.007985224087466, 0.007374028710215, 0.007187944540946, 0.006838016532435, 0.006577043144098]\n",
    "\n",
    "time_series_data_7 = [0.00951258, 0.02407533, 0.01565422, 0.0, 1.04877035, -0.07470716, np.sqrt(0.00413135),\n",
    "    0.01020326268631, 0.009768267929635]\n",
    "time_series_data_11 = [0.00643884, 0.01740896, 0.0112156, 0.0, 1.10547981, -0.1245054, np.sqrt(0.00368004),\n",
    "    0.00692964502549, 0.006645629100376]\n",
    "\n",
    "new_7 = [0.00926221, 0.01963079, 0.01034362, 0.0, 1.20388368, -0.22446884, np.sqrt(0.00495803), 0.009882415226021,\n",
    "    0.010207401448971]\n",
    "new_7 = [0.00683802, 0.02407533, 0.00483438, 0.0, 1.08987579, -0.09888466, np.sqrt(0.00210162), \n",
    "    0.007187944540946, 0.006838016532435]\n",
    "new_11 = [0.00496131, 0.01740896, 0.0043539, 0.0, 1.12791817, -0.13644296, np.sqrt(0.00189557), \n",
    "    0.005290328560701, 0.004961305864535]\n",
    "\n",
    "time_series_data = time_series_data_7\n",
    "time_series = run_robot.SimpleTimeSeries(*time_series_data_11)\n",
    "eicu = [time_series.iterate() for i in range(duration)]\n",
    "plt.plot(eicu)\n",
    "plt.plot(real_data)\n",
    "for i in range(100):\n",
    "    time_series.reset()\n",
    "    random_traj = [time_series.iterate(random=True) for i in range(duration)]\n",
    "    plt.plot(random_traj, color=\"C0\", alpha=0.1)\n",
    "\n",
    "\n",
    "time_series = run_robot.SimpleTimeSeries(*new_11)\n",
    "eicu = [time_series.iterate() for i in range(duration)]\n",
    "plt.plot(eicu, color=\"C1\")\n",
    "plt.plot(real_data)\n",
    "for i in range(100):\n",
    "    time_series.reset()\n",
    "    random_traj = [time_series.iterate(random=True) for i in range(duration)]\n",
    "    plt.plot(random_traj, color=\"C1\", alpha=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}